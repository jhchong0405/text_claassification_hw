{
    "ml_results": [
        {
            "max_features": 500,
            "min_df": 3,
            "model_name": "Random Forest",
            "accuracy": 0.802,
            "time": 1.2344908714294434,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.86      0.74      0.80       526\n           1       0.75      0.87      0.81       474\n\n    accuracy                           0.80      1000\n   macro avg       0.81      0.81      0.80      1000\nweighted avg       0.81      0.80      0.80      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 3,
            "model_name": "Logistic Regression",
            "accuracy": 0.836,
            "time": 0.05011892318725586,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.83      0.84       526\n           1       0.82      0.84      0.83       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 3,
            "model_name": "Linear SVM",
            "accuracy": 0.83,
            "time": 0.09713935852050781,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.82      0.84       526\n           1       0.81      0.84      0.82       474\n\n    accuracy                           0.83      1000\n   macro avg       0.83      0.83      0.83      1000\nweighted avg       0.83      0.83      0.83      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 3,
            "model_name": "Naive Bayes",
            "accuracy": 0.821,
            "time": 0.005291938781738281,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.80      0.82       526\n           1       0.79      0.85      0.82       474\n\n    accuracy                           0.82      1000\n   macro avg       0.82      0.82      0.82      1000\nweighted avg       0.82      0.82      0.82      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 5,
            "model_name": "Random Forest",
            "accuracy": 0.803,
            "time": 1.226008415222168,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.74      0.80       526\n           1       0.75      0.88      0.81       474\n\n    accuracy                           0.80      1000\n   macro avg       0.81      0.81      0.80      1000\nweighted avg       0.81      0.80      0.80      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 5,
            "model_name": "Logistic Regression",
            "accuracy": 0.836,
            "time": 0.048899173736572266,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.83      0.84       526\n           1       0.82      0.84      0.83       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 5,
            "model_name": "Linear SVM",
            "accuracy": 0.83,
            "time": 0.09766101837158203,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.82      0.84       526\n           1       0.81      0.84      0.82       474\n\n    accuracy                           0.83      1000\n   macro avg       0.83      0.83      0.83      1000\nweighted avg       0.83      0.83      0.83      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 5,
            "model_name": "Naive Bayes",
            "accuracy": 0.821,
            "time": 0.005242586135864258,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.80      0.82       526\n           1       0.79      0.85      0.82       474\n\n    accuracy                           0.82      1000\n   macro avg       0.82      0.82      0.82      1000\nweighted avg       0.82      0.82      0.82      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 10,
            "model_name": "Random Forest",
            "accuracy": 0.799,
            "time": 1.216536045074463,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.72      0.79       526\n           1       0.74      0.88      0.81       474\n\n    accuracy                           0.80      1000\n   macro avg       0.81      0.80      0.80      1000\nweighted avg       0.81      0.80      0.80      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 10,
            "model_name": "Logistic Regression",
            "accuracy": 0.835,
            "time": 0.04787492752075195,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.83      0.84       526\n           1       0.82      0.84      0.83       474\n\n    accuracy                           0.83      1000\n   macro avg       0.83      0.84      0.83      1000\nweighted avg       0.84      0.83      0.84      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 10,
            "model_name": "Linear SVM",
            "accuracy": 0.829,
            "time": 0.09735941886901855,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.82      0.84       526\n           1       0.81      0.84      0.82       474\n\n    accuracy                           0.83      1000\n   macro avg       0.83      0.83      0.83      1000\nweighted avg       0.83      0.83      0.83      1000\n"
        },
        {
            "max_features": 500,
            "min_df": 10,
            "model_name": "Naive Bayes",
            "accuracy": 0.822,
            "time": 0.0053899288177490234,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.80      0.83       526\n           1       0.79      0.85      0.82       474\n\n    accuracy                           0.82      1000\n   macro avg       0.82      0.82      0.82      1000\nweighted avg       0.82      0.82      0.82      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 3,
            "model_name": "Random Forest",
            "accuracy": 0.803,
            "time": 1.0007002353668213,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.73      0.80       526\n           1       0.75      0.88      0.81       474\n\n    accuracy                           0.80      1000\n   macro avg       0.81      0.81      0.80      1000\nweighted avg       0.81      0.80      0.80      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 3,
            "model_name": "Logistic Regression",
            "accuracy": 0.857,
            "time": 0.04731392860412598,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       526\n           1       0.84      0.86      0.85       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 3,
            "model_name": "Linear SVM",
            "accuracy": 0.855,
            "time": 0.11595487594604492,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       526\n           1       0.84      0.85      0.85       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.86      0.85      0.86      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 3,
            "model_name": "Naive Bayes",
            "accuracy": 0.844,
            "time": 0.005778312683105469,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       526\n           1       0.82      0.86      0.84       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 5,
            "model_name": "Random Forest",
            "accuracy": 0.811,
            "time": 1.016268253326416,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.75      0.81       526\n           1       0.76      0.88      0.81       474\n\n    accuracy                           0.81      1000\n   macro avg       0.82      0.81      0.81      1000\nweighted avg       0.82      0.81      0.81      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 5,
            "model_name": "Logistic Regression",
            "accuracy": 0.857,
            "time": 0.04705929756164551,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       526\n           1       0.84      0.86      0.85       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 5,
            "model_name": "Linear SVM",
            "accuracy": 0.855,
            "time": 0.11754679679870605,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       526\n           1       0.84      0.85      0.85       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.86      0.85      0.86      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 5,
            "model_name": "Naive Bayes",
            "accuracy": 0.844,
            "time": 0.006307125091552734,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       526\n           1       0.82      0.86      0.84       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 10,
            "model_name": "Random Forest",
            "accuracy": 0.803,
            "time": 1.0061297416687012,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.74      0.80       526\n           1       0.75      0.88      0.81       474\n\n    accuracy                           0.80      1000\n   macro avg       0.81      0.81      0.80      1000\nweighted avg       0.81      0.80      0.80      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 10,
            "model_name": "Logistic Regression",
            "accuracy": 0.857,
            "time": 0.04724287986755371,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       526\n           1       0.84      0.86      0.85       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 10,
            "model_name": "Linear SVM",
            "accuracy": 0.855,
            "time": 0.11682319641113281,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.86      0.86       526\n           1       0.84      0.85      0.85       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.86      0.85      0.86      1000\n"
        },
        {
            "max_features": 1000,
            "min_df": 10,
            "model_name": "Naive Bayes",
            "accuracy": 0.844,
            "time": 0.00586700439453125,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       526\n           1       0.82      0.86      0.84       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 3,
            "model_name": "Random Forest",
            "accuracy": 0.79,
            "time": 0.8622286319732666,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.73      0.78       526\n           1       0.74      0.86      0.79       474\n\n    accuracy                           0.79      1000\n   macro avg       0.80      0.79      0.79      1000\nweighted avg       0.80      0.79      0.79      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 3,
            "model_name": "Logistic Regression",
            "accuracy": 0.861,
            "time": 0.06340336799621582,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.87       526\n           1       0.84      0.87      0.86       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 3,
            "model_name": "Linear SVM",
            "accuracy": 0.855,
            "time": 0.14159512519836426,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86       526\n           1       0.84      0.86      0.85       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.86      0.85      1000\nweighted avg       0.86      0.85      0.86      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 3,
            "model_name": "Naive Bayes",
            "accuracy": 0.848,
            "time": 0.0063440799713134766,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       526\n           1       0.82      0.86      0.84       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 5,
            "model_name": "Random Forest",
            "accuracy": 0.807,
            "time": 0.8482942581176758,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.74      0.80       526\n           1       0.75      0.88      0.81       474\n\n    accuracy                           0.81      1000\n   macro avg       0.81      0.81      0.81      1000\nweighted avg       0.82      0.81      0.81      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 5,
            "model_name": "Logistic Regression",
            "accuracy": 0.86,
            "time": 0.06568622589111328,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.86       526\n           1       0.84      0.87      0.86       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 5,
            "model_name": "Linear SVM",
            "accuracy": 0.852,
            "time": 0.14113211631774902,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.84      0.86       526\n           1       0.83      0.86      0.85       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 5,
            "model_name": "Naive Bayes",
            "accuracy": 0.845,
            "time": 0.006294727325439453,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       526\n           1       0.82      0.86      0.84       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.85      0.84      1000\nweighted avg       0.85      0.84      0.85      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 10,
            "model_name": "Random Forest",
            "accuracy": 0.797,
            "time": 0.8362143039703369,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.72      0.79       526\n           1       0.74      0.89      0.81       474\n\n    accuracy                           0.80      1000\n   macro avg       0.81      0.80      0.80      1000\nweighted avg       0.81      0.80      0.80      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 10,
            "model_name": "Logistic Regression",
            "accuracy": 0.861,
            "time": 0.06309008598327637,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.87       526\n           1       0.84      0.87      0.86       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 10,
            "model_name": "Linear SVM",
            "accuracy": 0.849,
            "time": 0.14406800270080566,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.84      0.85       526\n           1       0.83      0.86      0.84       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n"
        },
        {
            "max_features": 2000,
            "min_df": 10,
            "model_name": "Naive Bayes",
            "accuracy": 0.846,
            "time": 0.006356954574584961,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.83      0.85       526\n           1       0.82      0.86      0.84       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 3,
            "model_name": "Random Forest",
            "accuracy": 0.797,
            "time": 0.7753539085388184,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.72      0.79       526\n           1       0.74      0.88      0.80       474\n\n    accuracy                           0.80      1000\n   macro avg       0.81      0.80      0.80      1000\nweighted avg       0.81      0.80      0.80      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 3,
            "model_name": "Logistic Regression",
            "accuracy": 0.86,
            "time": 0.09689021110534668,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.86       526\n           1       0.84      0.87      0.86       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 3,
            "model_name": "Linear SVM",
            "accuracy": 0.853,
            "time": 0.15532255172729492,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.84      0.86       526\n           1       0.83      0.86      0.85       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 3,
            "model_name": "Naive Bayes",
            "accuracy": 0.842,
            "time": 0.007107973098754883,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.85      0.85       526\n           1       0.83      0.84      0.83       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 5,
            "model_name": "Random Forest",
            "accuracy": 0.812,
            "time": 0.7748596668243408,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.76      0.81       526\n           1       0.77      0.87      0.81       474\n\n    accuracy                           0.81      1000\n   macro avg       0.82      0.81      0.81      1000\nweighted avg       0.82      0.81      0.81      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 5,
            "model_name": "Logistic Regression",
            "accuracy": 0.857,
            "time": 0.0924837589263916,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.86       526\n           1       0.84      0.87      0.85       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 5,
            "model_name": "Linear SVM",
            "accuracy": 0.851,
            "time": 0.12969970703125,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.84      0.86       526\n           1       0.83      0.86      0.85       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 5,
            "model_name": "Naive Bayes",
            "accuracy": 0.841,
            "time": 0.006539344787597656,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.85       526\n           1       0.83      0.84      0.83       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 10,
            "model_name": "Random Forest",
            "accuracy": 0.816,
            "time": 0.7919895648956299,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.88      0.75      0.81       526\n           1       0.76      0.89      0.82       474\n\n    accuracy                           0.82      1000\n   macro avg       0.82      0.82      0.82      1000\nweighted avg       0.83      0.82      0.82      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 10,
            "model_name": "Logistic Regression",
            "accuracy": 0.858,
            "time": 0.08476710319519043,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.86       526\n           1       0.84      0.87      0.85       474\n\n    accuracy                           0.86      1000\n   macro avg       0.86      0.86      0.86      1000\nweighted avg       0.86      0.86      0.86      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 10,
            "model_name": "Linear SVM",
            "accuracy": 0.848,
            "time": 0.13245844841003418,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.87      0.84      0.85       526\n           1       0.83      0.86      0.84       474\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n"
        },
        {
            "max_features": 3000,
            "min_df": 10,
            "model_name": "Naive Bayes",
            "accuracy": 0.838,
            "time": 0.006587505340576172,
            "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.85       526\n           1       0.83      0.83      0.83       474\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.84      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n"
        }
    ]
}