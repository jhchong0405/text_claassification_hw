{
    "dl_results": [
        {
            "batch_size": 16,
            "max_length": 64,
            "learning_rate": 1e-05,
            "accuracy": 0.8662,
            "time": 157.34556317329407,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.88      0.85      0.86      5027\n         1.0       0.85      0.88      0.87      4973\n\n    accuracy                           0.87     10000\n   macro avg       0.87      0.87      0.87     10000\nweighted avg       0.87      0.87      0.87     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8514024268947683,
            "recall_pos": 0.8811582545747034,
            "f1_neg": 0.8648211759951505,
            "f1_pos": 0.8675509800039597
        },
        {
            "batch_size": 16,
            "max_length": 64,
            "learning_rate": 2e-05,
            "accuracy": 0.8563,
            "time": 163.30487370491028,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.85      0.87      0.86      5027\n         1.0       0.86      0.84      0.85      4973\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8695046747563159,
            "recall_pos": 0.8429519404785843,
            "f1_neg": 0.8588269967580313,
            "f1_pos": 0.8536808878932899
        },
        {
            "batch_size": 16,
            "max_length": 64,
            "learning_rate": 3e-05,
            "accuracy": 0.8449,
            "time": 165.52149939537048,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.83      0.87      0.85      5027\n         1.0       0.86      0.82      0.84      4973\n\n    accuracy                           0.84     10000\n   macro avg       0.85      0.84      0.84     10000\nweighted avg       0.85      0.84      0.84     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8732842649691664,
            "recall_pos": 0.816207520611301,
            "f1_neg": 0.8498693253315265,
            "f1_pos": 0.8395904436860068
        },
        {
            "batch_size": 16,
            "max_length": 128,
            "learning_rate": 1e-05,
            "accuracy": 0.9045,
            "time": 187.07525730133057,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.90      0.91      0.91      5027\n         1.0       0.91      0.90      0.90      4973\n\n    accuracy                           0.90     10000\n   macro avg       0.90      0.90      0.90     10000\nweighted avg       0.90      0.90      0.90     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8543863139049135,
            "recall_pos": 0.947717675447416,
            "f1_neg": 0.8964725527029848,
            "f1_pos": 0.9047801881359187
        },
        {
            "batch_size": 16,
            "max_length": 128,
            "learning_rate": 2e-05,
            "accuracy": 0.9061,
            "time": 186.61216616630554,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.92      0.89      0.90      5027\n         1.0       0.89      0.93      0.91      4973\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.885020887209071,
            "recall_pos": 0.9274080032173738,
            "f1_neg": 0.9045440683135102,
            "f1_pos": 0.9076060218439437
        },
        {
            "batch_size": 16,
            "max_length": 128,
            "learning_rate": 3e-05,
            "accuracy": 0.9028,
            "time": 186.9036967754364,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.92      0.89      0.90      5027\n         1.0       0.89      0.92      0.90      4973\n\n    accuracy                           0.90     10000\n   macro avg       0.90      0.90      0.90     10000\nweighted avg       0.90      0.90      0.90     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8862144420131292,
            "recall_pos": 0.9195656545344862,
            "f1_neg": 0.9016393442622951,
            "f1_pos": 0.9039335837121962
        },
        {
            "batch_size": 16,
            "max_length": 256,
            "learning_rate": 1e-05,
            "accuracy": 0.9333,
            "time": 343.39443135261536,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.93      0.94      0.93      5027\n         1.0       0.94      0.93      0.93      4973\n\n    accuracy                           0.93     10000\n   macro avg       0.93      0.93      0.93     10000\nweighted avg       0.93      0.93      0.93     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9391287049930376,
            "recall_pos": 0.9274080032173738,
            "f1_neg": 0.9340191908200614,
            "f1_pos": 0.932564958042665
        },
        {
            "batch_size": 16,
            "max_length": 256,
            "learning_rate": 2e-05,
            "accuracy": 0.9287,
            "time": 344.0736436843872,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.95      0.91      0.93      5027\n         1.0       0.91      0.95      0.93      4973\n\n    accuracy                           0.93     10000\n   macro avg       0.93      0.93      0.93     10000\nweighted avg       0.93      0.93      0.93     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9506664014322658,
            "recall_pos": 0.9064950733963403,
            "f1_neg": 0.9305812481744717,
            "f1_pos": 0.9267139479905439
        },
        {
            "batch_size": 16,
            "max_length": 256,
            "learning_rate": 3e-05,
            "accuracy": 0.9279,
            "time": 348.7413957118988,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.93      0.92      0.93      5027\n         1.0       0.92      0.93      0.93      4973\n\n    accuracy                           0.93     10000\n   macro avg       0.93      0.93      0.93     10000\nweighted avg       0.93      0.93      0.93     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8852198130097474,
            "recall_pos": 0.9619947717675448,
            "f1_neg": 0.9207531553900269,
            "f1_pos": 0.925875749951616
        },
        {
            "batch_size": 32,
            "max_length": 64,
            "learning_rate": 1e-05,
            "accuracy": 0.8638,
            "time": 98.68150925636292,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.87      0.86      0.86      5027\n         1.0       0.86      0.87      0.86      4973\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.857569126715735,
            "recall_pos": 0.8700985320731952,
            "f1_neg": 0.8635817307692307,
            "f1_pos": 0.864017571884984
        },
        {
            "batch_size": 32,
            "max_length": 64,
            "learning_rate": 2e-05,
            "accuracy": 0.8603,
            "time": 99.16947269439697,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.88      0.84      0.86      5027\n         1.0       0.85      0.88      0.86      4973\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8410582852595981,
            "recall_pos": 0.8797506535290569,
            "f1_neg": 0.8582157718461382,
            "f1_pos": 0.8623238395584902
        },
        {
            "batch_size": 32,
            "max_length": 64,
            "learning_rate": 3e-05,
            "accuracy": 0.8592,
            "time": 97.91619062423706,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.86      0.86      0.86      5027\n         1.0       0.86      0.86      0.86      4973\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8555798687089715,
            "recall_pos": 0.862859440981299,
            "f1_neg": 0.8593406593406593,
            "f1_pos": 0.859059059059059
        },
        {
            "batch_size": 32,
            "max_length": 128,
            "learning_rate": 1e-05,
            "accuracy": 0.9076,
            "time": 161.8592939376831,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.92      0.89      0.91      5027\n         1.0       0.89      0.92      0.91      4973\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8903918838273324,
            "recall_pos": 0.9249949728534084,
            "f1_neg": 0.9064398541919805,
            "f1_pos": 0.9087317265902806
        },
        {
            "batch_size": 32,
            "max_length": 128,
            "learning_rate": 2e-05,
            "accuracy": 0.9057,
            "time": 161.89201998710632,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.92      0.89      0.90      5027\n         1.0       0.89      0.92      0.91      4973\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8874079968171872,
            "recall_pos": 0.9241906293987533,
            "f1_neg": 0.9044095286365941,
            "f1_pos": 0.9069560927479033
        },
        {
            "batch_size": 32,
            "max_length": 128,
            "learning_rate": 3e-05,
            "accuracy": 0.9001,
            "time": 159.5758819580078,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.89      0.91      0.90      5027\n         1.0       0.91      0.89      0.90      4973\n\n    accuracy                           0.90     10000\n   macro avg       0.90      0.90      0.90     10000\nweighted avg       0.90      0.90      0.90     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8597573105231748,
            "recall_pos": 0.9366579529459079,
            "f1_neg": 0.894453642384106,
            "f1_pos": 0.9013157894736842
        },
        {
            "batch_size": 32,
            "max_length": 256,
            "learning_rate": 1e-05,
            "accuracy": 0.9337,
            "time": 296.39527440071106,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.94      0.92      0.93      5027\n         1.0       0.92      0.95      0.93      4973\n\n    accuracy                           0.93     10000\n   macro avg       0.93      0.93      0.93     10000\nweighted avg       0.93      0.93      0.93     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9224189377362244,
            "recall_pos": 0.9451035592197868,
            "f1_neg": 0.9332796618697796,
            "f1_pos": 0.9341150750273278
        },
        {
            "batch_size": 32,
            "max_length": 256,
            "learning_rate": 2e-05,
            "accuracy": 0.9295,
            "time": 296.9117486476898,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.95      0.90      0.93      5027\n         1.0       0.91      0.96      0.93      4973\n\n    accuracy                           0.93     10000\n   macro avg       0.93      0.93      0.93     10000\nweighted avg       0.93      0.93      0.93     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8842251840063656,
            "recall_pos": 0.9706414639050874,
            "f1_neg": 0.9243085880640466,
            "f1_pos": 0.9298786361009439
        },
        {
            "batch_size": 32,
            "max_length": 256,
            "learning_rate": 3e-05,
            "accuracy": 0.936,
            "time": 297.0061001777649,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.94      0.93      0.94      5027\n         1.0       0.93      0.94      0.94      4973\n\n    accuracy                           0.94     10000\n   macro avg       0.94      0.94      0.94     10000\nweighted avg       0.94      0.94      0.94     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9285856375571911,
            "recall_pos": 0.9434948723104766,
            "f1_neg": 0.9358460304731354,
            "f1_pos": 0.9361532322426178
        },
        {
            "batch_size": 64,
            "max_length": 64,
            "learning_rate": 1e-05,
            "accuracy": 0.8595,
            "time": 81.5035138130188,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.84      0.90      0.87      5027\n         1.0       0.89      0.82      0.85      4973\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8967575094489756,
            "recall_pos": 0.821837924793887,
            "f1_neg": 0.8651760867479129,
            "f1_pos": 0.8533249817308697
        },
        {
            "batch_size": 64,
            "max_length": 64,
            "learning_rate": 2e-05,
            "accuracy": 0.8572,
            "time": 80.61790990829468,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.89      0.81      0.85      5027\n         1.0       0.83      0.90      0.86      4973\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8120151183608514,
            "recall_pos": 0.9028755278503922,
            "f1_neg": 0.8511259382819016,
            "f1_pos": 0.8627978478093774
        },
        {
            "batch_size": 64,
            "max_length": 64,
            "learning_rate": 3e-05,
            "accuracy": 0.8609,
            "time": 81.07764053344727,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.86      0.87      0.86      5027\n         1.0       0.87      0.85      0.86      4973\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.8701014521583449,
            "recall_pos": 0.8515986326161271,
            "f1_neg": 0.8628069829371733,
            "f1_pos": 0.858939255653585
        },
        {
            "batch_size": 64,
            "max_length": 128,
            "learning_rate": 1e-05,
            "accuracy": 0.9106,
            "time": 135.33961462974548,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.91      0.91      0.91      5027\n         1.0       0.91      0.91      0.91      4973\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9073005768848219,
            "recall_pos": 0.9139352503519003,
            "f1_neg": 0.9107428115015974,
            "f1_pos": 0.9104567307692308
        },
        {
            "batch_size": 64,
            "max_length": 128,
            "learning_rate": 2e-05,
            "accuracy": 0.9052,
            "time": 135.79325342178345,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.89      0.92      0.91      5027\n         1.0       0.92      0.89      0.90      4973\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9285856375571911,
            "recall_pos": 0.8781419666197466,
            "f1_neg": 0.9063197747791477,
            "f1_pos": 0.9005052067223425
        },
        {
            "batch_size": 64,
            "max_length": 128,
            "learning_rate": 3e-05,
            "accuracy": 0.9077,
            "time": 135.70823693275452,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.91      0.91      0.91      5027\n         1.0       0.91      0.91      0.91      4973\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9236124925402824,
            "recall_pos": 0.8894027749849186,
            "f1_neg": 0.9086105675146771,
            "f1_pos": 0.9044989775051124
        },
        {
            "batch_size": 64,
            "max_length": 256,
            "learning_rate": 1e-05,
            "accuracy": 0.9335,
            "time": 289.66356682777405,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.94      0.93      0.93      5027\n         1.0       0.93      0.94      0.93      4973\n\n    accuracy                           0.93     10000\n   macro avg       0.93      0.93      0.93     10000\nweighted avg       0.93      0.93      0.93     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9275910085538094,
            "recall_pos": 0.9394731550372009,
            "f1_neg": 0.9334400960864778,
            "f1_pos": 0.933559796183435
        },
        {
            "batch_size": 64,
            "max_length": 256,
            "learning_rate": 2e-05,
            "accuracy": 0.9376,
            "time": 288.24997210502625,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.94      0.94      0.94      5027\n         1.0       0.94      0.94      0.94      4973\n\n    accuracy                           0.94     10000\n   macro avg       0.94      0.94      0.94     10000\nweighted avg       0.94      0.94      0.94     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.9377362243883032,
            "recall_pos": 0.937462296400563,
            "f1_neg": 0.9379228014325507,
            "f1_pos": 0.9372738238841979
        },
        {
            "batch_size": 64,
            "max_length": 256,
            "learning_rate": 3e-05,
            "accuracy": 0.932,
            "time": 286.78021717071533,
            "classification_report": "              precision    recall  f1-score   support\n\n         0.0       0.93      0.94      0.93      5027\n         1.0       0.94      0.92      0.93      4973\n\n    accuracy                           0.93     10000\n   macro avg       0.93      0.93      0.93     10000\nweighted avg       0.93      0.93      0.93     10000\n",
            "model_name": "RoBERTa",
            "recall_neg": 0.945096479013328,
            "recall_pos": 0.9165493665795295,
            "f1_neg": 0.9322083782988326,
            "f1_pos": 0.9295401244009381
        }
    ]
}